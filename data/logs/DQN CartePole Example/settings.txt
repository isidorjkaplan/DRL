Command Arguments: Namespace(agents_path='data/agents.txt', debug=False, ensemble_path='data/ensemble.txt', env='CartPole-v0')

Agents Configuration File:
	ValueAgent --net=Linear --train=dqn --model=dqn-linear.pt --deterministic=True
	RandomAgent

Ensemble Configuration File: EpsilonGreedy --epsilon_start=0.7 --epsilon_finish=0.1 --epsilon_decay=0.00001

Trainer={'debug': True, 'agent': <src.agents.ValueAgent object at 0x7fd22bee0130>, 'backup_file': None, 'last_iter_time': 1609872080.988254, 'plotter': <src.plotting.Plotter object at 0x7fd22be7df40>, 'tag': 'ValueAgent net_Linear train_dqn model_dqnlinear_pt deterministic_True', 'iter_num': 0, 'save_every': 50, 'optimizer': Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.01
    weight_decay: 0
), 'episode_queue': <queue.Queue object at 0x7fd22bee0220>, 'batch_queue': <queue.Queue object at 0x7fd22bed1eb0>, 'tgt_net': Linear(
  (linear): Sequential(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ReLU()
  )
  (policy): Linear(in_features=64, out_features=2, bias=True)
  (value): Linear(in_features=64, out_features=1, bias=True)
  (advantages): Linear(in_features=64, out_features=2, bias=True)
), 'replay_buffer': deque([]), 'batch_size': 10, 'gamma': 1, 'sync_target': 10, 'max_buffer_size': 10000, 'episode_num': 0}
Agent (ValueAgent --net=Linear --train=dqn --model=dqn-linear.pt --deterministic=True
): Agent={'net': Linear(
  (linear): Sequential(
    (0): Linear(in_features=4, out_features=64, bias=True)
    (1): ReLU()
  )
  (policy): Linear(in_features=64, out_features=2, bias=True)
  (value): Linear(in_features=64, out_features=1, bias=True)
  (advantages): Linear(in_features=64, out_features=2, bias=True)
), 'debug': False, 'tag': 'ValueAgent net_Linear train_dqn model_dqnlinear_pt deterministic_True', 'n_actions': 2, 'write_file': <_io.TextIOWrapper name='data/logs/05_01_2021 13_41_20/agent_logs/ValueAgent net_Linear train_dqn model_dqnlinear_pt deterministic_True.csv' mode='w' encoding='UTF-8'>, 'csv_writer': <_csv.writer object at 0x7fd22be8ab80>, 'epsilon': 0, 'deterministic': True, 'headers': ['argmax A(s,a)', 'V(s)', 'A(s,a=0)', 'A(s,a=1)']}

Agent (RandomAgent
): Agent={'n_actions': 2, 'tag': 'RandomAgent'}

Agent (EpsilonGreedy --epsilon_start=0.7 --epsilon_finish=0.1 --epsilon_decay=0.00001): Agent={'n_actions': 2, 'env': <SelectAgentWrapper<TimeLimit<CartPoleEnv<CartPole-v0>>>>, 'epsilon_schedule': Epsilon(start=0.7, finish=0.1, decay=1e-05), 'epsilon': 0.7, 'tag': 'EpsilonGreedy epsilon_start_0_7 epsilon_finish_0_1 epsilon_decay_0_00001'}

